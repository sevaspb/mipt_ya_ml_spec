{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Линейная регрессия и стохастический градиентный спуск"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание основано на материалах лекций по линейной регрессии и градиентному спуску. Вы будете прогнозировать выручку компании в зависимости от уровня ее инвестиций в рекламу по TV, в газетах и по радио."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вы научитесь:\n",
    "- решать задачу восстановления линейной регрессии\n",
    "- реализовывать стохастический градиентный спуск для ее настройки\n",
    "- решать задачу линейной регрессии аналитически"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Введение\n",
    "Линейная регрессия - один из наиболее хорошо изученных методов машинного обучения, позволяющий прогнозировать значения количественного признака в виде линейной комбинации прочих признаков с параметрами - весами модели. Оптимальные (в смысле минимальности некоторого функционала ошибки) параметры линейной регрессии можно найти аналитически с помощью нормального уравнения или численно с помощью методов оптимизации.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Линейная регрессия использует простой функционал качества - среднеквадратичную ошибку. Мы будем работать с выборкой, содержащей 3 признака. Для настройки параметров (весов) модели решается следующая задача:\n",
    "$$\\Large \\frac{1}{\\ell}\\sum_{i=1}^\\ell{{((w_0 + w_1x_{i1} + w_2x_{i2} +  w_3x_{i3}) - y_i)}^2} \\rightarrow \\min_{w_0, w_1, w_2, w_3},$$\n",
    "где $x_{i1}, x_{i2}, x_{i3}$ - значения признаков $i$-го объекта, $y_i$ - значение целевого признака $i$-го объекта, $\\ell$ - число объектов в обучающей выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Градиентный спуск\n",
    "Параметры $w_0, w_1, w_2, w_3$, по которым минимизируется среднеквадратичная ошибка, можно находить численно с помощью градиентного спуска.\n",
    "Градиентный шаг для весов будет выглядеть следующим образом:\n",
    "$$\\Large w_0 \\leftarrow w_0 - \\frac{2\\eta}{\\ell} \\sum_{i=1}^\\ell{{((w_0 + w_1x_{i1} + w_2x_{i2} +  w_3x_{i3}) - y_i)}}$$\n",
    "$$\\Large w_j \\leftarrow w_j - \\frac{2\\eta}{\\ell} \\sum_{i=1}^\\ell{{x_{ij}((w_0 + w_1x_{i1} + w_2x_{i2} +  w_3x_{i3}) - y_i)}},\\ j \\in \\{1,2,3\\}$$\n",
    "Здесь $\\eta$ - параметр, шаг градиентного спуска."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Стохастический градиентный спуск\n",
    "Проблема градиентного спуска, описанного выше, в том, что на больших выборках считать на каждом шаге градиент по всем имеющимся данным может быть очень вычислительно сложно. \n",
    "В стохастическом варианте градиентного спуска поправки для весов вычисляются только с учетом одного случайно взятого объекта обучающей выборки:\n",
    "$$\\Large w_0 \\leftarrow w_0 - \\frac{2\\eta}{\\ell} {((w_0 + w_1x_{k1} + w_2x_{k2} +  w_3x_{k3}) - y_k)}$$\n",
    "$$\\Large w_j \\leftarrow w_j - \\frac{2\\eta}{\\ell} {x_{kj}((w_0 + w_1x_{k1} + w_2x_{k2} +  w_3x_{k3}) - y_k)},\\ j \\in \\{1,2,3\\},$$\n",
    "где $k$ - случайный индекс, $k \\in \\{1, \\ldots, \\ell\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Нормальное уравнение \n",
    "Нахождение вектора оптимальных весов $w$ может быть сделано и аналитически.\n",
    "Мы хотим найти такой вектор весов $w$, чтобы вектор $y$, приближающий целевой признак, получался умножением матрицы $X$ (состоящей из всех признаков объектов обучающей выборки, кроме целевого) на вектор весов $w$. То есть, чтобы выполнялось матричное уравнение:\n",
    "$$\\Large y = Xw$$\n",
    "Домножением слева на $X^T$ получаем:\n",
    "$$\\Large X^Ty = X^TXw$$\n",
    "Это хорошо, поскольку теперь матрица $X^TX$ - квадратная, и можно найти решение (вектор $w$) в виде:\n",
    "$$\\Large w = {(X^TX)}^{-1}X^Ty$$\n",
    "Матрица ${(X^TX)}^{-1}X^T$ - [*псевдообратная*](https://ru.wikipedia.org/wiki/Псевдообратная_матрица) для матрицы $X$. В NumPy такую матрицу можно вычислить с помощью функции [numpy.linalg.pinv](http://docs.scipy.org/doc/numpy-1.10.0/reference/generated/numpy.linalg.pinv.html).\n",
    "\n",
    "Однако, нахождение псевдообратной матрицы - операция вычислительно сложная и нестабильная в случае малого определителя матрицы $X$ (проблема мультиколлинеарности). \n",
    "На практике лучше находить вектор весов $w$ решением матричного уравнения \n",
    "$$\\Large X^TXw = X^Ty$$Это может быть сделано с помощью функции [numpy.linalg.solve](http://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.linalg.solve.html).\n",
    "\n",
    "Но все же на практике для больших матриц $X$ быстрее работает градиентный спуск, особенно его стохастическая версия."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Инструкции по выполнению"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В начале напишем простую функцию для записи ответов в текстовый файл. Ответами будут числа, полученные в ходе решения этого задания, округленные до 3 знаков после запятой. Полученные файлы после выполнения задания надо отправить в форму на странице задания на Coursera.org."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_answer_to_file(answer, filename):\n",
    "    with open(filename, 'w') as f_out:\n",
    "        f_out.write(str(round(answer, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Загрузите данные из файла *advertising.csv* в объект pandas DataFrame. [Источник данных](http://www-bcf.usc.edu/~gareth/ISL/data.html).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "adver_data = pd.read_csv('advertising.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Посмотрите на первые 5 записей и на статистику признаков в этом наборе данных.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               TV       Radio   Newspaper       Sales\n",
      "count  200.000000  200.000000  200.000000  200.000000\n",
      "mean   147.042500   23.264000   30.554000   14.022500\n",
      "std     85.854236   14.846809   21.778621    5.217457\n",
      "min      0.700000    0.000000    0.300000    1.600000\n",
      "25%     74.375000    9.975000   12.750000   10.375000\n",
      "50%    149.750000   22.900000   25.750000   12.900000\n",
      "75%    218.825000   36.525000   45.100000   17.400000\n",
      "max    296.400000   49.600000  114.000000   27.000000\n"
     ]
    }
   ],
   "source": [
    "print(adver_data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TV  Radio  Newspaper  Sales\n",
       "1  230.1   37.8       69.2   22.1\n",
       "2   44.5   39.3       45.1   10.4\n",
       "3   17.2   45.9       69.3    9.3\n",
       "4  151.5   41.3       58.5   18.5\n",
       "5  180.8   10.8       58.4   12.9"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adver_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Создайте массивы NumPy *X* из столбцов TV, Radio и Newspaper и *y* - из столбца Sales. Используйте атрибут *values* объекта pandas DataFrame.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = np.array([adver_data['TV'].values, adver_data['Radio'].values, adver_data['Newspaper'].values])\n",
    "y = np.array(adver_data['Sales'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Отмасштабируйте столбцы матрицы *X*, вычтя из каждого значения среднее по соответствующему столбцу и поделив результат на стандартное отклонение. Для определенности, используйте методы mean и std векторов NumPy (реализация std в Pandas может отличаться). Обратите внимание, что в numpy вызов функции .mean() без параметров возвращает среднее по всем элементам массива, а не по столбцам, как в pandas. Чтобы произвести вычисление по столбцам, необходимо указать параметр axis.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 147.0425   23.264    30.554 ]\n",
      "[ 85.63933176  14.80964564  21.72410606]\n"
     ]
    }
   ],
   "source": [
    "means, stds = X.mean(axis=1), X.std(axis=1)# Ваш код здесь\n",
    "print(means)\n",
    "print(stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.array([(col - means[idx])/stds[idx] for idx, col in enumerate(X)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Добавьте к матрице *X* столбец из единиц, используя методы *hstack*, *ones* и *reshape* библиотеки NumPy. Вектор из единиц нужен для того, чтобы не обрабатывать отдельно коэффициент $w_0$ линейной регрессии.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "size = X[0].size\n",
    "ones = np.ones(size)\n",
    "X = np.hstack(X)\n",
    "X = np.hstack((X, np.ones(size))).reshape((4, size))\n",
    "X = X.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Реализуйте функцию *mserror* - среднеквадратичную ошибку прогноза. Она принимает два аргумента - объекты Series *y* (значения целевого признака) и *y\\_pred* (предсказанные значения). Не используйте в этой функции циклы - тогда она будет вычислительно неэффективной.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mserror(y, y_pred):\n",
    "    return np.sum(np.power(y - y_pred, 2)) / y.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какова среднеквадратичная ошибка прогноза значений Sales, если всегда предсказывать медианное значение Sales по исходной выборке? Запишите ответ в файл '1.txt'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.34575\n"
     ]
    }
   ],
   "source": [
    "answer1 = mserror(y, np.median(y))# Ваш код здесь\n",
    "print(answer1)\n",
    "write_answer_to_file(answer1, '1.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Реализуйте функцию *normal_equation*, которая по заданным матрицам (массивам NumPy) *X* и *y* вычисляет вектор весов $w$ согласно нормальному уравнению линейной регрессии.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normal_equation(X, y):\n",
    "    X_1 = np.linalg.pinv(X)  # Ваш код здесь\n",
    "    return np.dot(X_1, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  3.91925365   2.79206274  -0.02253861  14.0225    ]\n"
     ]
    }
   ],
   "source": [
    "norm_eq_weights = normal_equation(X, y)\n",
    "print(norm_eq_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какие продажи предсказываются линейной моделью с весами, найденными с помощью нормального уравнения, в случае средних инвестиций в рекламу по ТВ, радио и в газетах? (то есть при нулевых значениях масштабированных признаков TV, Radio и Newspaper). Запишите ответ в файл '2.txt'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.0225\n"
     ]
    }
   ],
   "source": [
    "answer2 = norm_eq_weights[-1]\n",
    "print(answer2)\n",
    "write_answer_to_file(answer2, '2.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Напишите функцию *linear_prediction*, которая принимает на вход матрицу *X* и вектор весов линейной модели *w*, а возвращает вектор прогнозов в виде линейной комбинации столбцов матрицы *X* с весами *w*.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linear_prediction(X, w):\n",
    "    return np.dot(X, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какова среднеквадратичная ошибка прогноза значений Sales в виде линейной модели с весами, найденными с помощью нормального уравнения? Запишите ответ в файл '3.txt'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.78412631451\n"
     ]
    }
   ],
   "source": [
    "answer3 = mserror(y, linear_prediction(X, norm_eq_weights))\n",
    "print(answer3)\n",
    "write_answer_to_file(answer3, '3.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Напишите функцию *stochastic_gradient_step*, реализующую шаг стохастического градиентного спуска для линейной регрессии. Функция должна принимать матрицу *X*, вектора *y* и *w*, число *train_ind* - индекс объекта обучающей выборки (строки матрицы *X*), по которому считается изменение весов, а также число *$\\eta$* (eta) - шаг градиентного спуска (по умолчанию *eta*=0.01). Результатом будет вектор обновленных весов. Наша реализация функции будет явно написана для данных с 3 признаками, но несложно модифицировать для любого числа признаков, можете это сделать.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stochastic_gradient_step(X, y, w, train_ind, eta=0.01):\n",
    "    x = X[train_ind]\n",
    "    l = X.size\n",
    "    grad0 = 2.0/l*x[0]*(np.dot(w, x) - y[train_ind])# Ваш код здесь\n",
    "    grad1 = 2.0/l*x[1]*(np.dot(w, x) - y[train_ind])# Ваш код здесь\n",
    "    grad2 = 2.0/l*x[2]*(np.dot(w, x) - y[train_ind])# Ваш код здесь\n",
    "    grad3 = 2.0/l*(np.dot(w, x) - y[train_ind])# Ваш код здесь\n",
    "\n",
    "#     grad = x * (2.0/l*(np.dot(w, x) - y[train_ind]))\n",
    "#     return  w - eta * grad#np.array([grad0, grad1, grad2, grad3])\n",
    "    return w - eta * np.array([grad0, grad1, grad2, grad3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Напишите функцию *stochastic_gradient_descent*, реализующую стохастический градиентный спуск для линейной регрессии. Функция принимает на вход следующие аргументы:**\n",
    "- X - матрица, соответствующая обучающей выборке\n",
    "- y - вектор значений целевого признака\n",
    "- w_init - вектор начальных весов модели\n",
    "- eta - шаг градиентного спуска (по умолчанию 0.01)\n",
    "- max_iter - максимальное число итераций градиентного спуска (по умолчанию 10000)\n",
    "- max_weight_dist - максимальное евклидово расстояние между векторами весов на соседних итерациях градиентного спуска,\n",
    "при котором алгоритм прекращает работу (по умолчанию 1e-8)\n",
    "- seed - число, используемое для воспроизводимости сгенерированных псевдослучайных чисел (по умолчанию 42)\n",
    "- verbose - флаг печати информации (например, для отладки, по умолчанию False)\n",
    "\n",
    "**На каждой итерации в вектор (список) должно записываться текущее значение среднеквадратичной ошибки. Функция должна возвращать вектор весов $w$, а также вектор (список) ошибок.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stochastic_gradient_descent(X, y, w_init, eta=1e-2, max_iter=1e4,\n",
    "                                min_weight_dist=1e-8, seed=42, verbose=False):\n",
    "    # Инициализируем расстояние между векторами весов на соседних\n",
    "    # итерациях большим числом. \n",
    "    weight_dist = np.inf\n",
    "    # Инициализируем вектор весов\n",
    "    w = w_init\n",
    "    # Сюда будем записывать ошибки на каждой итерации\n",
    "    errors = []\n",
    "    # Счетчик итераций\n",
    "    iter_num = 0\n",
    "    # Будем порождать псевдослучайные числа \n",
    "    # (номер объекта, который будет менять веса), а для воспроизводимости\n",
    "    # этой последовательности псевдослучайных чисел используем seed.\n",
    "    np.random.seed(seed)\n",
    "        \n",
    "    # Основной цикл\n",
    "    while weight_dist > min_weight_dist and iter_num < max_iter:\n",
    "        # порождаем псевдослучайный \n",
    "        # индекс объекта обучающей выборки\n",
    "        random_ind = np.random.randint(X.shape[0])\n",
    "        \n",
    "        # вычисляем новые значения\n",
    "        new_w = stochastic_gradient_step(X, y, w, random_ind, eta)\n",
    "        \n",
    "        # добавляем ошибку в стейт\n",
    "        errors = np.append(errors, mserror(y, linear_prediction(X, new_w)))\n",
    "        \n",
    "        # Евклидово расстояние\n",
    "        weight_dist = np.linalg.norm(w - new_w)\n",
    "        w = new_w\n",
    "        iter_num += 1\n",
    "        \n",
    "        if verbose:\n",
    "            print(weight_dist) \n",
    "            print(errors)\n",
    "        \n",
    "    print(weight_dist)\n",
    "    return w, errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Запустите $10^5$ итераций стохастического градиентного спуска. Укажите вектор начальных весов *w_init*, состоящий из нулей. Оставьте параметры  *eta* и *seed* равными их значениям по умолчанию (*eta*=0.01, *seed*=42 - это важно для проверки ответов).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.41090542449e-05\n",
      "[  3.61401132   2.49893374   0.23920167  12.87021689]\n",
      "4.30590825091\n",
      "CPU times: user 9.73 s, sys: 348 ms, total: 10.1 s\n",
      "Wall time: 11.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stoch_grad_desc_weights, stoch_errors_by_iter = stochastic_gradient_descent(X, y, w_init=np.array([0, 0, 0, 0]), eta=1e-2, max_iter=1e5,\n",
    "                                min_weight_dist=1e-8, seed=42, verbose=False)\n",
    "print(stoch_grad_desc_weights)\n",
    "print(stoch_errors_by_iter[-1])\n",
    "# print(X[0])\n",
    "# print(mserror(y, linear_prediction(X, [ 0.03084642, -0.06444348, -0.02545895, -0.03651611])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрим, чему равна ошибка на первых 50 итерациях стохастического градиентного спуска. Видим, что ошибка не обязательно уменьшается на каждой итерации.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x10e80d358>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQSIiIlXyfw1eH6iucfuZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10ee603c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pylab inline\n",
    "plot(range(50), stoch_errors_by_iter[:50])\n",
    "xlabel('Iteration number')\n",
    "ylabel('MSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Теперь посмотрим на зависимость ошибки от номера итерации для $10^5$ итераций стохастического градиентного спуска. Видим, что алгоритм сходится.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x11243bdd8>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nh/6lVuSI0DkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1124c7588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pylab inline\n",
    "plot(range(len(stoch_errors_by_iter)), stoch_errors_by_iter)\n",
    "xlabel('Iteration number')\n",
    "ylabel('MSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрим на вектор весов, к которому сошелся метод.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3.61401132,   2.49893374,   0.23920167,  12.87021689])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoch_grad_desc_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрим на среднеквадратичную ошибку на последней итерации.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.3059082509096234"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoch_errors_by_iter[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какова среднеквадратичная ошибка прогноза значений Sales в виде линейной модели с весами, найденными с помощью градиентного спуска? Запишите ответ в файл '4.txt'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.30590825091\n"
     ]
    }
   ],
   "source": [
    "\n",
    "answer4 = mserror(y, linear_prediction(X, stoch_grad_desc_weights))\n",
    "print(answer4)\n",
    "write_answer_to_file(answer4, '4.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ответами к заданию будут текстовые файлы, полученные в ходе этого решения. Обратите внимание, что отправленные файлы не должны содержать пустую строку в конце. Данный нюанс является ограничением платформы Coursera. Мы работаем над исправлением этого ограничения.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
